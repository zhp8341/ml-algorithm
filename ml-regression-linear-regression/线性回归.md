## 一、什么是线性回归

~~~~
线性回归算法是一种基本的机器学习算法，用于建立一个线性模型来预测自变量和因变量之间的关系。

ŷ = β₀ + β₁x₁ + β₂x₂ + ... + βᵢxᵢ

其中，ŷ是因变量（要预测的目标值）的预测值，β₀是截距项，β₁至βᵢ是各自变量的系数，x₁至xᵢ是自变量（影响因素）。

~~~~

## 二、线性回归算法

~~~  

线性回归是一种基本的机器学习算法，常用的线性回归算法包括以下几种：

1、最小二乘法（Ordinary Least Squares, OLS）：最小二乘法是一种基于误差平方和最小化的方法，通过寻找能够使得误差平方和最小的最佳系数来建立线性回归模型。最小二乘法适用于数据量较小、噪声较少的情况。

2、梯度下降法（Gradient Descent, GD）：梯度下降法是一种迭代优化算法，通过不断迭代，调整模型参数来最小化误差函数，并求解出最佳系数。梯度下降法适用于大规模数据集、高维数据及非线性回归问题。

3、正规方程法（Normal Equation, NE）：正规方程法是一种基于矩阵求逆运算的方法，直接求解最小化误差函数的最佳系数。正规方程法适用于数据量较小、数据较为简单的情况。

4、岭回归（Ridge Regression）：岭回归是一种常用的正则化线性回归算法，通过对模型系数进行约束，避免模型过拟合的问题，并提高了模型的泛化能力。

5、Lasso回归（Least Absolute Shrinkage and Selection Operator, LASSO）：Lasso回归是一种基于正则化的线性回归算法，通过缩减模型系数的大小，可以把不重要的特征系数降为0，从而达到特征选择的目的。

以上是线性回归中常用的几种算法，其中每种算法都有其优缺点和适用范围。根据实际问题和数据的特点，选择合适的算法对于建立一个良好的线性回归模型至关重要。
~~~

## 三、线性回归损失函数计算方式

~~~~
线性回归的损失函数通常采用均方误差（Mean Squared Error, MSE）作为衡量预测值与真实值之间差距的指标，即：

MSE = (1 / n) * Σ(yi - ŷi)²

其中，yi表示真实值，ŷi表示模型预测值，n是样本数。

除此之外，还有其他可用于线性回归的损失函数。以下是一些常见的线性回归损失函数：

1、平均绝对误差（Mean Absolute Error, MAE）：MAE是另一种评估预测值与真实值之间差距的指标，它计算的是预测值与真实值之差的绝对值的平均值。MAE相比MSE更加偏向于对异常值不敏感。

2、Huber损失函数（Huber Loss）：Huber损失函数是一种介于MSE和MAE之间的损失函数，它对误差的大小进行了阈值化处理。当误差小于等于阈值时，用MSE，否则用MAE作为损失函数。

3、对数损失函数（Logarithmic Loss）：对数损失函数也称为交叉熵损失函数，它在分类问题中较常见，但在线性回归中也有应用。对数损失函数将预测值和真实值之间的差异进行了对数化处理，可以更好地处理极端情况和异常值。

以上是一些常见的线性回归损失函数。在实际应用中，选择合适的损失函数需要根据数据的特点和任务要求进行权衡考虑。
~~~~

## 四、其他说明

~~~~

LinearRegression 是 Scikit-learn 库中的一个线性回归模型，基于最小二乘法 (OLS) 实现。OLS 是一种统计学方法，用于估计线性回归模型的系数。简单来说，线性回归模型通过对自变量和因变量之间的关系进行建模，从而预测新的观测值的因变量值。
LinearRegression 可以接受多个参数，下面是一些重要的参数及其含义：
fit_intercept：是否拟合截距。如果设置为 False，则模型不会拟合任何截距。默认为 True。
normalize：当 fit_intercept 设置为 True 时，是否对自变量进行标准化。标准化可以将所有自变量缩放到(0,1)之间的值。默认为 False。
copy_X：是否复制 X 数组。如果设置为 True，X 数组的副本将存储在 LinearRegression 对象中，否则将只存储引用。默认为 True。
n_jobs：指定用于计算的 CPU 数量。默认为 1，即使用单个 CPU 计算。如果设置为 -1，则使用所有可用的 CPU 计算（一般推荐）。
这些参数通常需要根据具体问题和数据集进行调整，以获得更好的性能。例如，对于已经进行了标准化处理的自变量，可以将 normalize 设置为 False，从而避免重复的标准化操作；如果数据集较大，可以增加 n_jobs 参数以提高计算速度等等。需要根据具体情况权衡取舍，进行参数的选择和优化。

线性回归可以用于许多领域，如经济学、营销学、社会学等等。它可以被用来预测股票价格、房价、销售额等等。在实际应用中，我们通常会使用统计软件来进行线性回归分析，并根据分析结果进行决策。
~~~~



## 五、代码例子说明

~~~~
lr1 :手动编写一个线性回归 ，一个变量 预测一下出生人口
lr2 :使用sklearn编写一个线性回归 ，一个变量预测一下出生人口
lr3 :梯度下降法
lr4 :预测波士顿房价的一个例子 包含模型的导出和导入 
~~~~